0.00-9.22建立web应用/app应用 替代工作
9.23-14.50  介绍安装 kaggle 数据集
14.50-26.41 
	1/databunch与pytorch数据结构介绍 创建databunch数据结构
		
		创建df
			df = pd.read_csv(path...)
		data block API
			DataSet - pytorch 数据结构
				包含 __getitem__  实现item[i]
					 __len__  实现 len(item)
			DataLoader - 组织dataset为batch送至GPU (dataset,batch_size)
			
			DataBunch - fastai 数据结构  DataBunch(tarin_dl:DataLoader, valid_dl:DataLoader...)
		
		综合流程	以https://docs.fast.ai/vision.data.html#ImageDataBunch 为准
			data = ImageDataBunch.from_csv
		分解流程	以https://docs.fast.ai/data_block.html 为准
					1/指定data目录
					2/区分数据集 测试/验证
					3/指定data对应label
					4/变换为指定的数据形状
					5/转换为DataBunch数据
			data = (ImageList.from_folder(path) #Where to find the data? -> in path and its subfolders
					.split_by_folder()              #How to split in train/valid? -> use the folders
					.label_from_folder()            #How to label? -> depending on the folder of the filenames
					.add_test_folder()              #Optionally add a test set (here default name is test)
					.transform(tfms, size=64)       #Data augmentation? -> use tfms with a size of 64
					.databunch())                   #Finally? -> use the defaults for conversion to ImageDataBunch
					
26.41-56.33 通用流程举例 1/亚马逊森林卫星数据 多标签分类

	29.00使用 api 快速再jupyter notebook内运行代码
	
		用例流程  ps: 代码变动很快
		30.21 - 入参介绍
		
		1/ src = (ImageFileList.from_folder(path)	# 将src 与 data 分割的原因在于 实际使用的数据集data一般为src的transform 后续修改transform后 src不变，但data改变
					.split_by_rand_pct(0.2)
					.label_from_df(label_delim=' '))
					
		2/ tfms = get_transforms(flip_vert = ...)
		   data = (src.datasets()
					.transform(tfms, size = )
					.databunch().normalize(imagenet_stats))
	
		3/ arch = model.sresnet50
		   acc_02 = partial(accuracy_thresh, thresh=0.2) # 创建入参thresh为 0.2 的 accuracy_thresh 函数模板 下同
		   f_score = partial(fbeta, thresh=0.2) #此处thresh 为可能标签的门限概率，高于该门限都认为是标签 fbeta() f_score函数
		   learn = create_cnn(data,arch,metrics=[acc_02, f_score])   
		   
		4/ learn.lr_find()
		   learn.recorder.plot()
		   lr = ..
		   
		5/ learn.fit_one_cycle(n, slice(lr))
		
		
	42.00 回答问题1/是否使用错误数据来增强模型 —— 记录并进行自动或手动微调
				  2/data block 原理 使用顺序 —— 见26.41
				  3/数据源推荐 未听懂

		6/ learn.save('stage-1-rn50')
		
		7/ learn.unfreeze()
		   learn.lr_find()
		   learn.recorder.plot()
		   learn.fit_one_cycle(5, slice(1e-5, lr/5))  # 此处可以用包含错误数据的新数据集训练  第二个参数一般选 freeze的 1/5 或 1/10
		
			data.c
			data.classes
	
	50.54 refine
	
		为何一开始 transform size不用256
			1/ 256极有可能过拟合
			2/ 128 数据集为原来的1/4大小且已经足够好
			
		8/  data = (src.transform(tfms, size=256)
					.databunch(num_workers=0).normalize(imagenet_stats))

			learn.data = data #更改源数据集
			data.train_ds[0][0].shape #查看数据集
			learn.freeze()	#只训练最后几层
			learn.lr_find()
			learn.recorder.plot()
			
			lr=...
			learn.fit_one_cycle(5, slice(lr))
			learn.save('stage-1-256-rn50')
			
			learn.unfreeze()
			learn.fit_one_cycle(5, slice(1e-5, lr/5))
			learn.recorder.plot_losses()
			learn.save('stage-2-256-rn50')

56.33- 通用流程举例 2/图形分割 Camvid用例
	
		将图形用相同数字标记
		下载已标记的图形集学习

1.00.27-1.03.06 回答问题 lr选择是否能直接返回数据

1.03.07-1.09.00 继续图形分割

1.09.01- 回答问题
		介绍unit技术
		介绍lr/weights选取技巧

1.33.00-
	3/回归 BIWI head pose
		imagee points
	
	4/NLP IMDB


note:
		查看 lr_find 图形中 loss 和 learning rate 关系
vocabulary
	Discriminative model 判别模型
	Generative model 生成模型
	Transfer learning 迁移学习
