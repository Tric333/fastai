0.00-9.22建立web应用/app应用 替代工作
9.23-14.50  介绍安装 kaggle 数据集
14.50-26.41 
	1/databunch与pytorch数据结构介绍 创建databunch数据结构
		
		创建df
			df = pd.read_csv(path...)
		data block API
			DataSet - pytorch 数据结构
				包含 __getitem__  实现item[i]
					 __len__  实现 len(item)
			DataLoader - 组织dataset为batch送至GPU (dataset,batch_size)
			
			DataBunch - fastai 数据结构  DataBunch(tarin_dl:DataLoader, valid_dl:DataLoader...)
		
		综合流程	以https://docs.fast.ai/vision.data.html#ImageDataBunch 为准
			data = ImageDataBunch.from_csv
		分解流程	以https://docs.fast.ai/data_block.html 为准
					1/指定data目录
					2/区分数据集 测试/验证
					3/指定data对应label
					4/变换为指定的数据形状
					5/转换为DataBunch数据
			data = (ImageList.from_folder(path) #Where to find the data? -> in path and its subfolders
					.split_by_folder()              #How to split in train/valid? -> use the folders
					.label_from_folder()            #How to label? -> depending on the folder of the filenames
					.add_test_folder()              #Optionally add a test set (here default name is test)
					.transform(tfms, size=64)       #Data augmentation? -> use tfms with a size of 64
					.databunch())                   #Finally? -> use the defaults for conversion to ImageDataBunch
					
26.41-56.33 通用流程举例 1/亚马逊森林卫星数据 多标签分类

	29.00使用 api 快速再jupyter notebook内运行代码
	
		用例流程  ps: 代码变动很快
		30.21 - 入参介绍
		# 源数据获取及处理
		0/ path = untar_data()
		   path.ls()
		   
		# 获取数据的标签及源数据地址
		1/ src = (ImageFileList.from_folder(path)	# 将src 与 data 分割的原因在于 实际使用的数据集data一般为src的transform 后续修改transform后 src不变，但data改变
					.split_by_rand_pct(0.2)
					.label_from_df(label_delim=' '))
		
		# 变换为所需databunch
		2/ tfms = get_transforms(flip_vert = ...)
		   data = (src.datasets()
					.transform(tfms, size = )
					.databunch().normalize(imagenet_stats))
			data.show_batch(rows=3, figsize=(12,9)) # 观察数据
			
		# 创建learn
		3/ arch = model.sresnet50
		   acc_02 = partial(accuracy_thresh, thresh=0.2) # 创建入参thresh为 0.2 的 accuracy_thresh 函数模板 下同
		   f_score = partial(fbeta, thresh=0.2) #此处thresh 为可能标签的门限概率，高于该门限都认为是标签 fbeta() f_score函数
		   learn = create_cnn(data,arch,metrics=[acc_02, f_score])   
		
		# learn参数确定
		4/ learn.lr_find()
		   learn.recorder.plot()
		   lr = ..
		
		# 训练并保存模型
		5/ learn.fit_one_cycle(n, slice(lr))
		   learn.save('stage-1-rn50')

		
	42.00 回答问题1/是否使用错误数据来增强模型 —— 记录并进行自动或手动微调
				  2/data block 原理 使用顺序 —— 见26.41
				  3/数据源推荐 未听懂

		# 训练所有cnn层
		6/ learn.unfreeze()
		   learn.lr_find()
		   learn.recorder.plot()
		   learn.fit_one_cycle(5, slice(1e-5, lr/5))  # 此处可以用包含错误数据的新数据集训练  第二个参数一般选 freeze的 1/5 或 1/10
		
			data.c
			data.classes
	
	50.54 refine
	
		为何一开始 transform size不用256
			1/ 256极有可能过拟合
			2/ 128 数据集为原来的1/4大小且已经足够好
			
		# 调优
		7/  data = (src.transform(tfms, size=256)
					.databunch(num_workers=0).normalize(imagenet_stats))

			learn.data = data #更改源数据集
			data.train_ds[0][0].shape #查看数据集
			learn.freeze()	#只训练最后几层
			learn.lr_find()
			learn.recorder.plot()
			
			lr=...
			learn.fit_one_cycle(5, slice(lr))
			learn.save('stage-1-256-rn50')
			
			learn.unfreeze()
			learn.fit_one_cycle(5, slice(1e-5, lr/5))
			learn.recorder.plot_losses()
			learn.save('stage-2-256-rn50')

56.33- 通用流程举例 2/图形分割 Camvid用例
	
		将图形用相同数字标记
		下载已标记的图形集学习

		# 源数据获取及处理
		0/ 下载并观察数据
			path = untar_data(URLs.CAMVID)
			path.ls()
			path_lbl = path/'labels'	#此处path_lbl为一路径
			path_img = path/'images'
			
			fnames = get_image_files(path_img)	#此处fnames 为所有image的路径
			fnames[:3]
			
			#查看图片
			img_f = fnames[0]
			img = open_image(img_f)
			img.show(figsize=(5,5))
			
			#查看mask
			get_y_fn = lambda x: path_lbl/f'{x.stem}_P{x.suffix}'
			mask = open_mask(get_y_fn(img_f))
			mask.show(figsize=(5,5), alpha=1)
			
			src_size = np.array(mask.shape[1:])
			src_size,mask.data
			
			#查看mask对应标签意义 此数据集保存在path/'codes.txt'内
			codes = np.loadtxt(path/'codes.txt', dtype=str); codes
		
		1/  增加部分入参
			src = (SegmentationItemList.from_folder(path_img)
				   .split_by_fname_file('../valid.txt') #验证集来源 未 randomly 因为可能使得训练集数据到验证集内，由于该训练集可能存在连续拍照的照片，若分散到验证集内会影响结果
				   .label_from_func(get_y_fn, classes=codes))  # label来源函数，对应的类名称
		 
		2/	
			size = src_size//2
			bs=8
			
			data = (src.transform(get_transforms(), size=size, tfm_y=True)	#此处tfm_y = True 意味 X与Y同时翻转 由于数据的特殊性，必须把标签和data同时翻转
					.databunch(bs=bs, num_workers=0)
					.normalize(imagenet_stats))
					
			data.show_batch(rows=3, figsize=(12,9)) #观察数据 测试集
			data.show_batch(2, figsize=(10,7), ds_type=DatasetType.Valid) # 验证集
			
		3/ 增加创建metrics评分模型的示例
			name2id = {v:k for k,v in enumerate(codes)}
			void_code = name2id['Void']

			def acc_camvid(input, target):
				target = target.squeeze(1)
				mask = target != void_code
				return (input.argmax(dim=1)[mask]==target[mask]).float().mean()
				
			metrics=acc_camvid
			wd=1e-2
			learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd)
		
		4/
			lr_find(learn)
			learn.recorder.plot()
			lr=3e-3
		
		5/
			learn.fit_one_cycle(10, slice(lr), pct_start=0.9)
			learn.save('stage-1')
			learn.show_results(rows=3, figsize=(8,9))
			
		6/
			learn.unfreeze()
			lrs = slice(lr/400,lr/4)
			learn.fit_one_cycle(12, lrs, pct_start=0.8)
			
		7/
		60.27-63.06 回答问题 lr选择是否能直接返回最优入参 —— 目前不行


		1.09.01- 回答问题
				介绍unit技术
				介绍lr/weights选取技巧

1.33.00-
	3/回归 BIWI head pose
		imagee points
	
	4/NLP IMDB


note:
		查看 lr_find 图形中 loss 和 learning rate 关系
		学习pandas numpy 等常用操作
		可在course.fast.ai/datasets 下载数据源
vocabulary
	Discriminative model 判别模型
	Generative model 生成模型
	Transfer learning 迁移学习
